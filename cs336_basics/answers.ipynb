{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bcd24d5-eb0d-4d1e-ad5b-caab72297493",
   "metadata": {},
   "source": [
    "# 2. BPE Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f953db-1617-4993-9d07-58e14875764e",
   "metadata": {},
   "source": [
    "## 2.1 The Unicode Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a740a-0f39-429a-855e-c28ac316b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord(\"Áâõ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afad214-4607-4646-ae05-d2488753a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(29275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b148521-5d41-4a57-b46f-c253b57c3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(0) # null , U+0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8895b-7713-4803-bada-7fa3b738f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord('\\x00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec303a-603a-4c3d-9880-7bd18eb08bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chr(0)) # not printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417fa0a-8e3c-45a1-932e-d7d0e21c8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a7452-bf20-402a-afd4-6a185dc02d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"this is a test\" + chr(0) + \"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8f5138-94e0-4e95-9741-f9659bfd8bb1",
   "metadata": {},
   "source": [
    "## 2.2 Unicode Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac071360-984a-4b79-8840-cf1b1bf25a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"hello! „Åì„Çì„Å´„Å°„ÅØ!\"\n",
    "utf8_encoded = test_string.encode(\"utf-8\")\n",
    "print(utf8_encoded)\n",
    "print(type(utf8_encoded))\n",
    "# Get the byte values for the encoded string (integers from 0 to 255).\n",
    "list(utf8_encoded)\n",
    "# One byte does not necessarily correspond to one Unicode character!\n",
    "print(len(test_string))\n",
    "print(len(utf8_encoded))\n",
    "print(utf8_encoded.decode(\"utf-8\"))\n",
    "print(list(utf8_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b2b5b-63b6-483a-ae21-b2b517cefd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with various strings\n",
    "test_strings = [\n",
    "    \"hello\",                    # Pure ASCII\n",
    "    \"hello! „Åì„Çì„Å´„Å°„ÅØ!\",        # Mixed ASCII and Japanese\n",
    "    \"Hello ‰∏ñÁïå\",                # Mixed ASCII and Chinese\n",
    "    \"üöÄ rocket\",                 # Emoji and ASCII\n",
    "    \"Caf√©\",                      # ASCII with accents\n",
    "]\n",
    "\n",
    "for s in test_strings:\n",
    "    utf8 = s.encode(\"utf-8\")\n",
    "    utf16 = s.encode(\"utf-16\")\n",
    "    utf32 = s.encode(\"utf-32\")\n",
    "    \n",
    "    print(f\"\\nString: '{s}'\")\n",
    "    print(f\"  Characters: {len(s)}\")\n",
    "    print(f\"  UTF-8:  {len(utf8):2d} bytes - {utf8}\")\n",
    "    print(f\"  UTF-16: {len(utf16):2d} bytes - {utf16}\")\n",
    "    print(f\"  UTF-32: {len(utf32):2d} bytes - {utf32}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1819fc-2470-4525-9526-8af08e27cd18",
   "metadata": {},
   "source": [
    "utf-8 encoding has fewer bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfd32d-7710-4978-b609-1218ed8e63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "\n",
    "decode_utf8_bytes_to_str_wrong(\"hello!\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb40e5f-2f77-4d40-8cef-30c21bbd6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_utf8_bytes_to_str_wrong(\"hello! „Åì„Çì„Å´„Å°„ÅØ!\".encode(\"utf-8\")) # Some characters require multiple bytes, one to one decoding cannot work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9cf75-9970-4d81-884c-102954321ee9",
   "metadata": {},
   "source": [
    "## 2.4 BPE Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6effe-22e1-488a-bdf1-1b1e78537b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "# Test Case 1: Basic contractions\n",
    "text1 = \"I'm happy, you're sad, they'll go, we've seen, it's fine\"\n",
    "print(re.findall(PAT, text1))\n",
    "\n",
    "# Test Case 2: Numbers\n",
    "text2 = \"There are 123 cats and 456 dogs in 2024\"\n",
    "print(re.findall(PAT, text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de2bab3-3508-4312-a7f4-b14c83d9f813",
   "metadata": {},
   "source": [
    "- add space to the next tokenÔºö\" hello\" ‚Üí [' hello']\n",
    "- split abbreviationsÔºö\"don't\" ‚Üí ['don', \"'t\"]\n",
    "- sum the signsÔºö\"!!!\" ‚Üí ['!!!']\n",
    "- unicode supported: with all languages and numbers\n",
    "- split numbers and lettersÔºö\"GPT4\" ‚Üí ['GPT', '4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa913b6",
   "metadata": {},
   "source": [
    "## 2.5 Experimenting with BPE Tokenizer Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787543e",
   "metadata": {},
   "source": [
    "- Problem (train_bpe_tinystories): BPE Training on TinyStories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55789d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpe_trainer import run_train_bpe, save_bpe_model, load_bpe_model\n",
    "\n",
    "input_path = \"data/TinyStoriesV2-GPT4-train.txt\"\n",
    "\n",
    "vocab, merges = run_train_bpe(\n",
    "    input_path=input_path,\n",
    "    vocab_size=10000,\n",
    "    special_tokens=[\"<|endoftext|>\"],\n",
    "    num_processes=10\n",
    ")\n",
    "\n",
    "save_bpe_model(vocab, merges, output_dir=\"bpe_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "# Launch snakeviz to visualize profiling results\n",
    "subprocess.Popen(['snakeviz', 'bpe.prof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpe_trainer_heap import run_train_bpe, save_bpe_model, load_bpe_model\n",
    "\n",
    "input_path = \"data/owt_train.txt\"\n",
    "\n",
    "vocab, merges = run_train_bpe(\n",
    "    input_path=input_path,\n",
    "    vocab_size=32000,\n",
    "    special_tokens=[\"<|endoftext|>\"],\n",
    "    num_processes=10\n",
    ")\n",
    "\n",
    "save_bpe_model(vocab, merges, output_dir=\"bpe_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e057725",
   "metadata": {},
   "source": [
    "mac with 16GB RAM and M4 processors\n",
    "\n",
    "| Rank | Function | Time (s) | % of Total | Calls | Issue |\n",
    "|------|----------|----------|------------|-------|-------|\n",
    "| 1 | run_train_bpe | 641.3 | 74.6% | 1 | Core BPE algorithm (unavoidable) |\n",
    "| 2 | posix.read | 111.5 | 13.0% | 76 | File I/O - reading chunks |\n",
    "| 3 | len() | 51.3 | 6.0% | 1.17B | **Excessive calls - can optimize** |\n",
    "| 4 | max() | 55.2 | 6.4% | 9,804 | Finding best pair each iteration |\n",
    "| 5 | lambda | 25.4 | 3.0% | 369M | Lambda overhead in max() |\n",
    "\n",
    "Already done dict.get and list.append opt, opted out 40% time during merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa40fbd",
   "metadata": {},
   "source": [
    "- Problem (train_bpe_expts_owt): BPE Training on OpenWebText\n",
    "\n",
    "    ```bash\n",
    "    uv run python train_bpe.py\n",
    "    ```\n",
    "\n",
    "    Total time: 14m 7.99s\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f49e9",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
